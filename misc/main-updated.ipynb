{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install keras\n",
        "# !pip install tensorflow\n",
        "# !pip install --upgrade keras tensorflow\n",
        "# !pip install --upgrade opencv-python\n",
        "# !pip install --upgrade pandas\n",
        "# !pip install --upgrade scipy"
      ],
      "metadata": {
        "id": "O95Y7_La3Zzz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import kagglehub\n",
        "\n",
        "# # Download latest version\n",
        "# path = kagglehub.dataset_download(\"ashishpatel26/facial-expression-recognitionferchallenge\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "SeGm8M0w3uRv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# # Define source and destination paths\n",
        "# source = \"/root/.cache/kagglehub/datasets/ashishpatel26/facial-expression-recognitionferchallenge/versions/1\"\n",
        "# destination = \"/content/dataset\"\n",
        "\n",
        "# # Move files to destination folder\n",
        "# shutil.move(source, destination)\n",
        "\n",
        "# print(f\"Files moved to {destination}\")\n"
      ],
      "metadata": {
        "id": "wS6mSGYh4Tix"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "GlNhFGvT3YN_"
      },
      "outputs": [],
      "source": [
        "import setuptools.dist\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.models import model_from_json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VszORWsj3YOB",
        "outputId": "ae708369-48fd-407a-8ad5-fea017583ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   emotion                                             pixels     Usage\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('fer2013.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "D3bUzOaK3YOB"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for index, row in df.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    if row['Usage'] == 'Training':\n",
        "        X_train.append(np.array(k))\n",
        "        y_train.append(row['emotion'])\n",
        "    elif row['Usage'] == 'PublicTest':\n",
        "        X_test.append(np.array(k))\n",
        "        y_test.append(row['emotion'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "YXrLmx_53YOC"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train, dtype = 'uint8')\n",
        "y_train = np.array(y_train, dtype = 'uint8')\n",
        "X_test = np.array(X_test, dtype = 'uint8')\n",
        "y_test = np.array(y_test, dtype = 'uint8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Normalize the pixel values\n",
        "# X_train = X_train / 255.0\n",
        "# X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "J6zYMsCdET9I"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "sfNqvJ7J3YOC"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "y_train= to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8YHmMXe-3YOC"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "iyqFex033YOC"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode = 'nearest')\n",
        "testgen = ImageDataGenerator(rescale=1./255)\n",
        "datagen.fit(X_train)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "plT-vZYM3YOD"
      },
      "outputs": [],
      "source": [
        "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "print(np.min(X_train), np.max(X_train))\n",
        "\n",
        "print(len(X_train) // batch_size)"
      ],
      "metadata": {
        "id": "ex2_JEg6COcy",
        "outputId": "9536b805-adf9-4a10-89fc-46a71b906f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28709, 48, 48, 1) (3589, 48, 48, 1)\n",
            "0 255\n",
            "448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "AjkbZ_ot3YOD"
      },
      "outputs": [],
      "source": [
        "# emotion_model = Sequential()\n",
        "\n",
        "# emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
        "#                          input_shape=(48, 48, 1)))\n",
        "# emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.25))\n",
        "\n",
        "# emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.25))\n",
        "\n",
        "# emotion_model.add(Flatten())\n",
        "# emotion_model.add(Dense(1024, activation='relu'))\n",
        "# emotion_model.add(Dropout(0.5))\n",
        "# emotion_model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "\n",
        "# #Different model\n",
        "# emotion_model = Sequential()\n",
        "\n",
        "# # First convolutional block\n",
        "# emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1), padding='same'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.3))\n",
        "\n",
        "# # Second convolutional block\n",
        "# emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.3))\n",
        "\n",
        "# # Third convolutional block\n",
        "# emotion_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "# emotion_model.add(BatchNormalization())\n",
        "# emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# emotion_model.add(Dropout(0.3))\n",
        "\n",
        "# # Flatten and fully connected layers\n",
        "# emotion_model.add(Flatten())\n",
        "# emotion_model.add(Dense(1024, activation='relu'))\n",
        "# emotion_model.add(Dropout(0.5))\n",
        "# emotion_model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# emotion_model.summary()\n",
        "\n",
        "# # cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "# # initial_learning_rate = 0.0001\n",
        "# # lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "# #                                decay_rate=0.96)\n",
        "\n",
        "# #optimizer = Adam(lr=0.0001, decay=1e-6) #Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "# emotion_model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "#                       metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Emotion_Model(input_shape=(48,48,1)):\n",
        "    # first input model\n",
        "    visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 7\n",
        "    #the 1-st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
        "    conv1_2 = BatchNormalization()(conv1_2)\n",
        "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
        "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
        "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
        "    conv2_1 = BatchNormalization()(conv2_1)\n",
        "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "    conv2_2 = BatchNormalization()(conv2_2)\n",
        "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "    conv2_2 = BatchNormalization()(conv2_3)\n",
        "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
        "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "    conv3_1 = BatchNormalization()(conv3_1)\n",
        "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "    conv3_2 = BatchNormalization()(conv3_2)\n",
        "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
        "    conv3_3 = BatchNormalization()(conv3_3)\n",
        "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "    conv3_4 = BatchNormalization()(conv3_4)\n",
        "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
        "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "    conv4_1 = BatchNormalization()(conv4_1)\n",
        "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "    conv4_2 = BatchNormalization()(conv4_2)\n",
        "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "    conv4_3 = BatchNormalization()(conv4_3)\n",
        "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "    conv4_4 = BatchNormalization()(conv4_4)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
        "\n",
        "    #the 5-th block\n",
        "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "    conv5_1 = BatchNormalization()(conv5_1)\n",
        "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "    conv5_2 = BatchNormalization()(conv5_2)\n",
        "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
        "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
        "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model\n",
        "    model = Model(inputs =visible, outputs = ouput)\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8jhAsFilHWD1"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Emotion_Model()\n",
        "# opt = Adam(lr=0.0001, decay=1e-6)\n",
        "# opt = Adam(learning_rate=1e-4)\n",
        "# optimizer with learning rate and decay:\n",
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps=100000,\n",
        "                               decay_rate=0.96)\n",
        "opt = Adam(learning_rate=lr_schedule)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yPb4PA3BHni0",
        "outputId": "f448ee97-ede0-4013-badd-550b958e8815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_70\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_70\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_103              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_104              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop1_1 (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_105              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_106              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop2_1 (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_108              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_109              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_110              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_4 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_111              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop3_1 (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_112              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_113              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_114              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_4 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_115              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool4_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop4_1 (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_116              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_2 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_117              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_118              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_4 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool5_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop5_1 (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m3,591\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_103              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_104              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_105              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_106              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_108              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_109              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_110              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_111              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop3_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_112              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_113              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_114              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_115              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop4_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_116              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_117              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_118              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv5_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool5_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop5_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,111,367\u001b[0m (50.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,111,367</span> (50.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,103,431\u001b[0m (49.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,103,431</span> (49.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,936\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T023D2Om3YOE",
        "outputId": "f2ed04bf-dbdc-4e04-ba5b-a3fec579368f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 101ms/step - accuracy: 0.2080 - loss: 2.1978 - val_accuracy: 0.2252 - val_loss: 1.9460\n",
            "Epoch 2/100\n",
            "\u001b[1m  1/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 70ms/step - accuracy: 0.1406 - loss: 1.8422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1406 - loss: 1.8422 - val_accuracy: 0.0000e+00 - val_loss: 1.9943\n",
            "Epoch 3/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.2504 - loss: 1.7902 - val_accuracy: 0.2581 - val_loss: 1.7934\n",
            "Epoch 4/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51us/step - accuracy: 0.2031 - loss: 1.7914 - val_accuracy: 0.4000 - val_loss: 1.8647\n",
            "Epoch 5/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - accuracy: 0.2831 - loss: 1.7474 - val_accuracy: 0.2846 - val_loss: 2.0623\n",
            "Epoch 6/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.3125 - loss: 1.6530 - val_accuracy: 0.6000 - val_loss: 1.4971\n",
            "Epoch 7/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.3232 - loss: 1.6931 - val_accuracy: 0.3186 - val_loss: 2.1793\n",
            "Epoch 8/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step - accuracy: 0.2969 - loss: 1.6553 - val_accuracy: 0.4000 - val_loss: 2.6202\n",
            "Epoch 9/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.3570 - loss: 1.6225 - val_accuracy: 0.3758 - val_loss: 1.8322\n",
            "Epoch 10/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.4375 - loss: 1.5159 - val_accuracy: 0.0000e+00 - val_loss: 2.9635\n",
            "Epoch 11/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - accuracy: 0.3912 - loss: 1.5491 - val_accuracy: 0.4188 - val_loss: 1.5372\n",
            "Epoch 12/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96us/step - accuracy: 0.4688 - loss: 1.4308 - val_accuracy: 0.4000 - val_loss: 1.7633\n",
            "Epoch 13/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - accuracy: 0.4337 - loss: 1.4744 - val_accuracy: 0.4802 - val_loss: 1.3868\n",
            "Epoch 14/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.3750 - loss: 1.5744 - val_accuracy: 0.4000 - val_loss: 1.0597\n",
            "Epoch 15/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 76ms/step - accuracy: 0.4505 - loss: 1.4156 - val_accuracy: 0.4735 - val_loss: 1.3932\n",
            "Epoch 16/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.5156 - loss: 1.2580 - val_accuracy: 0.6000 - val_loss: 0.9508\n",
            "Epoch 17/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 76ms/step - accuracy: 0.4800 - loss: 1.3549 - val_accuracy: 0.5167 - val_loss: 1.2721\n",
            "Epoch 18/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48us/step - accuracy: 0.4688 - loss: 1.4146 - val_accuracy: 0.2000 - val_loss: 1.6697\n",
            "Epoch 19/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.4987 - loss: 1.3155 - val_accuracy: 0.5405 - val_loss: 1.2436\n",
            "Epoch 20/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67us/step - accuracy: 0.5156 - loss: 1.2384 - val_accuracy: 0.4000 - val_loss: 0.8671\n",
            "Epoch 21/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.5175 - loss: 1.2606 - val_accuracy: 0.5469 - val_loss: 1.2062\n",
            "Epoch 22/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.4531 - loss: 1.3692 - val_accuracy: 0.4000 - val_loss: 1.4277\n",
            "Epoch 23/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.5336 - loss: 1.2219 - val_accuracy: 0.5474 - val_loss: 1.2101\n",
            "Epoch 24/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.5938 - loss: 1.0669 - val_accuracy: 0.2000 - val_loss: 1.1787\n",
            "Epoch 25/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - accuracy: 0.5467 - loss: 1.1866 - val_accuracy: 0.5703 - val_loss: 1.1721\n",
            "Epoch 26/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50us/step - accuracy: 0.5312 - loss: 1.2177 - val_accuracy: 0.4000 - val_loss: 1.0125\n",
            "Epoch 27/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.5589 - loss: 1.1698 - val_accuracy: 0.5653 - val_loss: 1.1530\n",
            "Epoch 28/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77us/step - accuracy: 0.5938 - loss: 1.1828 - val_accuracy: 0.4000 - val_loss: 1.9900\n",
            "Epoch 29/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.5710 - loss: 1.1396 - val_accuracy: 0.5672 - val_loss: 1.1617\n",
            "Epoch 30/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.5625 - loss: 1.1022 - val_accuracy: 1.0000 - val_loss: 0.1971\n",
            "Epoch 31/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.5770 - loss: 1.1211 - val_accuracy: 0.5759 - val_loss: 1.1302\n",
            "Epoch 32/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52us/step - accuracy: 0.6562 - loss: 1.0239 - val_accuracy: 1.0000 - val_loss: 0.3865\n",
            "Epoch 33/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.5847 - loss: 1.0958 - val_accuracy: 0.5932 - val_loss: 1.0989\n",
            "Epoch 34/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.6562 - loss: 1.0048 - val_accuracy: 0.2000 - val_loss: 1.5593\n",
            "Epoch 35/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 78ms/step - accuracy: 0.5943 - loss: 1.0736 - val_accuracy: 0.5954 - val_loss: 1.0959\n",
            "Epoch 36/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65us/step - accuracy: 0.6406 - loss: 0.9582 - val_accuracy: 0.6000 - val_loss: 1.1994\n",
            "Epoch 37/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - accuracy: 0.6062 - loss: 1.0442 - val_accuracy: 0.5898 - val_loss: 1.0795\n",
            "Epoch 38/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.6094 - loss: 0.9260 - val_accuracy: 0.4000 - val_loss: 1.2691\n",
            "Epoch 39/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.6156 - loss: 1.0280 - val_accuracy: 0.5918 - val_loss: 1.1002\n",
            "Epoch 40/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5781 - loss: 1.0350 - val_accuracy: 0.6000 - val_loss: 1.0408\n",
            "Epoch 41/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 77ms/step - accuracy: 0.6159 - loss: 1.0153 - val_accuracy: 0.6007 - val_loss: 1.0641\n",
            "Epoch 42/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80us/step - accuracy: 0.5312 - loss: 1.1382 - val_accuracy: 0.6000 - val_loss: 0.8530\n",
            "Epoch 43/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.6258 - loss: 0.9938 - val_accuracy: 0.6217 - val_loss: 1.0237\n",
            "Epoch 44/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.7344 - loss: 0.8664 - val_accuracy: 0.6000 - val_loss: 1.5962\n",
            "Epoch 45/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.6320 - loss: 0.9831 - val_accuracy: 0.6309 - val_loss: 1.0407\n",
            "Epoch 46/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.6094 - loss: 1.1960 - val_accuracy: 0.6000 - val_loss: 1.0664\n",
            "Epoch 47/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 78ms/step - accuracy: 0.6357 - loss: 0.9633 - val_accuracy: 0.6200 - val_loss: 1.0385\n",
            "Epoch 48/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63us/step - accuracy: 0.6250 - loss: 1.0533 - val_accuracy: 0.6000 - val_loss: 1.3467\n",
            "Epoch 49/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 77ms/step - accuracy: 0.6398 - loss: 0.9506 - val_accuracy: 0.6250 - val_loss: 1.0178\n",
            "Epoch 50/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.6875 - loss: 0.9107 - val_accuracy: 0.6000 - val_loss: 1.1177\n",
            "Epoch 51/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.6518 - loss: 0.9343 - val_accuracy: 0.6222 - val_loss: 1.0085\n",
            "Epoch 52/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7031 - loss: 0.9778 - val_accuracy: 0.8000 - val_loss: 0.7907\n",
            "Epoch 53/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.6522 - loss: 0.9230 - val_accuracy: 0.6108 - val_loss: 1.0645\n",
            "Epoch 54/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7656 - loss: 0.7963 - val_accuracy: 0.6000 - val_loss: 1.6470\n",
            "Epoch 55/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.6563 - loss: 0.9150 - val_accuracy: 0.6336 - val_loss: 1.0243\n",
            "Epoch 56/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76us/step - accuracy: 0.6875 - loss: 0.9082 - val_accuracy: 0.6000 - val_loss: 0.6550\n",
            "Epoch 57/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.6652 - loss: 0.8939 - val_accuracy: 0.6395 - val_loss: 1.0187\n",
            "Epoch 58/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48us/step - accuracy: 0.6406 - loss: 1.0487 - val_accuracy: 0.8000 - val_loss: 0.6512\n",
            "Epoch 59/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - accuracy: 0.6676 - loss: 0.8806 - val_accuracy: 0.6560 - val_loss: 0.9727\n",
            "Epoch 60/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.5781 - loss: 0.9398 - val_accuracy: 0.4000 - val_loss: 2.2048\n",
            "Epoch 61/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.6801 - loss: 0.8638 - val_accuracy: 0.6381 - val_loss: 1.0035\n",
            "Epoch 62/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.7344 - loss: 0.8886 - val_accuracy: 1.0000 - val_loss: 0.5089\n",
            "Epoch 63/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 76ms/step - accuracy: 0.6808 - loss: 0.8586 - val_accuracy: 0.6445 - val_loss: 0.9910\n",
            "Epoch 64/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52us/step - accuracy: 0.7812 - loss: 0.7302 - val_accuracy: 0.4000 - val_loss: 1.1172\n",
            "Epoch 65/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.6784 - loss: 0.8501 - val_accuracy: 0.6482 - val_loss: 0.9625\n",
            "Epoch 66/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51us/step - accuracy: 0.6250 - loss: 0.9222 - val_accuracy: 0.4000 - val_loss: 1.0338\n",
            "Epoch 67/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.6875 - loss: 0.8348 - val_accuracy: 0.6376 - val_loss: 0.9944\n",
            "Epoch 68/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95us/step - accuracy: 0.6875 - loss: 0.8521 - val_accuracy: 0.4000 - val_loss: 1.4049\n",
            "Epoch 69/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 76ms/step - accuracy: 0.6936 - loss: 0.8220 - val_accuracy: 0.6540 - val_loss: 0.9881\n",
            "Epoch 70/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.5938 - loss: 0.9030 - val_accuracy: 0.8000 - val_loss: 0.7542\n",
            "Epoch 71/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.6996 - loss: 0.8047 - val_accuracy: 0.6504 - val_loss: 0.9680\n",
            "Epoch 72/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.6250 - loss: 0.9909 - val_accuracy: 0.6000 - val_loss: 0.6806\n",
            "Epoch 73/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7045 - loss: 0.7984 - val_accuracy: 0.6602 - val_loss: 0.9576\n",
            "Epoch 74/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7031 - loss: 0.8791 - val_accuracy: 0.4000 - val_loss: 1.5634\n",
            "Epoch 75/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7029 - loss: 0.7886 - val_accuracy: 0.6515 - val_loss: 0.9825\n",
            "Epoch 76/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.6719 - loss: 0.7613 - val_accuracy: 0.2000 - val_loss: 1.4357\n",
            "Epoch 77/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 76ms/step - accuracy: 0.7074 - loss: 0.7923 - val_accuracy: 0.6465 - val_loss: 0.9843\n",
            "Epoch 78/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46us/step - accuracy: 0.7031 - loss: 0.7609 - val_accuracy: 0.4000 - val_loss: 1.4058\n",
            "Epoch 79/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 76ms/step - accuracy: 0.7126 - loss: 0.7718 - val_accuracy: 0.6663 - val_loss: 0.9635\n",
            "Epoch 80/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53us/step - accuracy: 0.7500 - loss: 0.7549 - val_accuracy: 0.6000 - val_loss: 1.0149\n",
            "Epoch 81/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7193 - loss: 0.7508 - val_accuracy: 0.6568 - val_loss: 0.9823\n",
            "Epoch 82/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.6719 - loss: 0.7519 - val_accuracy: 0.6000 - val_loss: 1.4134\n",
            "Epoch 83/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - accuracy: 0.7230 - loss: 0.7416 - val_accuracy: 0.6632 - val_loss: 0.9949\n",
            "Epoch 84/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48us/step - accuracy: 0.7188 - loss: 0.7856 - val_accuracy: 0.6000 - val_loss: 0.4335\n",
            "Epoch 85/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7233 - loss: 0.7455 - val_accuracy: 0.6735 - val_loss: 0.9611\n",
            "Epoch 86/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103us/step - accuracy: 0.5938 - loss: 1.0831 - val_accuracy: 0.4000 - val_loss: 1.3268\n",
            "Epoch 87/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7275 - loss: 0.7268 - val_accuracy: 0.6596 - val_loss: 0.9884\n",
            "Epoch 88/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47us/step - accuracy: 0.6719 - loss: 0.9788 - val_accuracy: 1.0000 - val_loss: 0.5350\n",
            "Epoch 89/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.7355 - loss: 0.7055 - val_accuracy: 0.6604 - val_loss: 0.9628\n",
            "Epoch 90/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.6562 - loss: 0.9241 - val_accuracy: 0.2000 - val_loss: 1.8864\n",
            "Epoch 91/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.7383 - loss: 0.7054 - val_accuracy: 0.6741 - val_loss: 0.9676\n",
            "Epoch 92/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52us/step - accuracy: 0.7031 - loss: 0.7675 - val_accuracy: 1.0000 - val_loss: 0.4222\n",
            "Epoch 93/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 76ms/step - accuracy: 0.7414 - loss: 0.6866 - val_accuracy: 0.6691 - val_loss: 0.9761\n",
            "Epoch 94/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50us/step - accuracy: 0.7812 - loss: 0.5545 - val_accuracy: 1.0000 - val_loss: 0.2276\n",
            "Epoch 95/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 77ms/step - accuracy: 0.7445 - loss: 0.6834 - val_accuracy: 0.6663 - val_loss: 0.9700\n",
            "Epoch 96/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49us/step - accuracy: 0.7188 - loss: 0.7518 - val_accuracy: 0.8000 - val_loss: 0.6451\n",
            "Epoch 97/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7443 - loss: 0.6803 - val_accuracy: 0.6582 - val_loss: 1.0244\n",
            "Epoch 98/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.8125 - loss: 0.6087 - val_accuracy: 0.6000 - val_loss: 1.8437\n",
            "Epoch 99/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 77ms/step - accuracy: 0.7519 - loss: 0.6682 - val_accuracy: 0.6814 - val_loss: 0.9601\n",
            "Epoch 100/100\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74us/step - accuracy: 0.5938 - loss: 1.0371 - val_accuracy: 0.2000 - val_loss: 1.6141\n"
          ]
        }
      ],
      "source": [
        "# emotion_model_info = emotion_model.fit(\n",
        "#         train_flow,\n",
        "#         # steps_per_epoch=len(X_train) / batch_size,\n",
        "#         steps_per_epoch=len(X_train)// batch_size,\n",
        "#         epochs=20,\n",
        "#         verbose=1,\n",
        "#         validation_data=test_flow,\n",
        "#         # validation_steps=len(X_test) / batch_size)\n",
        "#         validation_steps=len(X_test)// batch_size)\n",
        "\n",
        "# emotion_model_info = model.fit(\n",
        "#         train_flow,\n",
        "#         steps_per_epoch=len(X_train)// batch_size,\n",
        "#         epochs=20,\n",
        "#         verbose=1,\n",
        "#         validation_data=test_flow,\n",
        "#         validation_steps=len(X_test)// batch_size)\n",
        "\n",
        "num_epochs = 100\n",
        "history = model.fit(train_flow,\n",
        "                    steps_per_epoch=len(X_train) // batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_flow,validation_steps=len(X_test) // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXBwGtTz3YOE",
        "outputId": "dae3da91-6e74-4041-a02d-314ab387ad65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.1712 - loss: 103.5672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101.9076919555664, 0.16968515515327454]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "#emotion_model.evaluate(X_test, y_test)\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb_QsV-n3YOE"
      },
      "outputs": [],
      "source": [
        "# model_json = emotion_model.to_json()\n",
        "# with open(\"model.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# emotion_model.save_weights(\"model.h5\")\n",
        "# print(\"Saved model to disk\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}