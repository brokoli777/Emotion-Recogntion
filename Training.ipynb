{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brokoli777/Emotion-Recogntion/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "krvR0qZRLe-a"
      },
      "outputs": [],
      "source": [
        "# Import libraries for data manipulation, visualization and warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "# Import tensorflow and keras for deep learning tools\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    MaxPooling2D,\n",
        "    BatchNormalization,\n",
        "    Activation,\n",
        "    LeakyReLU,\n",
        "    GlobalAveragePooling2D,\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "TARGET_SIZE = (48, 48)  # Target image size for resizing\n",
        "INPUT_SHAPE = (48, 48, 1)  # grayscale image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdciVX-Rasmm",
        "outputId": "33dac721-7574-438f-d93b-0a9006dd92e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/msambare/fer2013?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60.3M/60.3M [00:02<00:00, 30.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/msambare/fer2013/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Import kagglehub to download datasets from Kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Download FER2013 dataset from Kaggle (didplay path for referrence)\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FuyDaaa-Le-f",
        "outputId": "eea6a292-c82b-4819-e6e0-3003216cab3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "Destination path '/content/dataset/1' already exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9ca5b423f2d0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Move dataset files from source to destination folder (display where moved to for referrence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Files moved to {destination}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Destination path '/content/dataset/1' already exists"
          ]
        }
      ],
      "source": [
        "# Import shutil library for file operations\n",
        "import shutil\n",
        "\n",
        "# Define source and destination paths for dataset\n",
        "source = \"/root/.cache/kagglehub/datasets/msambare/fer2013/versions/1\"\n",
        "destination = \"/content/dataset\"\n",
        "\n",
        "# Move dataset files from source to destination folder (display where moved to for referrence)\n",
        "shutil.move(source, destination)\n",
        "print(f\"Files moved to {destination}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o9VvUHrdNKd"
      },
      "outputs": [],
      "source": [
        "# Define the paths for training and testing directories\n",
        "TRAIN_DIR = './dataset/train'\n",
        "TEST_DIR = './dataset/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE_rBK-UexMi"
      },
      "outputs": [],
      "source": [
        "# Display the contents of the dataset directories\n",
        "print(os.listdir(TRAIN_DIR))\n",
        "print(os.listdir(TEST_DIR))\n",
        "print(len(os.listdir(TRAIN_DIR+'/angry')))\n",
        "print(len(os.listdir(TRAIN_DIR+'/disgust')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkCyRXRDeYZK"
      },
      "outputs": [],
      "source": [
        "# Function to load the dataset images and their labels\n",
        "def load_dataset(directory):\n",
        "    image_paths = []  # List for storing image paths\n",
        "    labels = []       # List for storing labels\n",
        "\n",
        "    # Iterate through each label in the dataset directory\n",
        "    for label in os.listdir(directory):\n",
        "        label_path = os.path.join(directory, label)  # Use os.path.join to create label path\n",
        "        if not os.path.isdir(label_path):  # Skip if it's not a directory\n",
        "            continue\n",
        "\n",
        "        # Iterate through the images within the label directory\n",
        "        for filename in os.listdir(label_path):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "                image_path = os.path.join(label_path, filename)\n",
        "                image_paths.append(image_path)  # Append image path\n",
        "                labels.append(label)            # Append label\n",
        "\n",
        "        # Display completion validation\n",
        "        print(label, \"Completed\")\n",
        "\n",
        "    return image_paths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Znj1sJeBcBrW"
      },
      "outputs": [],
      "source": [
        "# Convert training dataset into a DataFrame\n",
        "train = pd.DataFrame()\n",
        "train['image'], train['label'] = load_dataset(TRAIN_DIR)\n",
        "\n",
        "# Mix up the training dataset\n",
        "# set seed for reproducibility\n",
        "train = train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train.head()\n",
        "\n",
        "\n",
        "test = pd.DataFrame()\n",
        "test['image'], test['label'] = load_dataset(TEST_DIR)\n",
        "test = test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM7MMRNJhAu3"
      },
      "outputs": [],
      "source": [
        "for label in os.listdir(TRAIN_DIR):\n",
        "    label_path = os.path.join(TRAIN_DIR, label)\n",
        "    if os.path.isdir(label_path):\n",
        "        print(f\"{label}: {len(os.listdir(label_path))} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymYLG9lggMxv"
      },
      "outputs": [],
      "source": [
        "def get_features(image_paths, target_size=(48, 48), color_mode='grayscale'):\n",
        "    img_features = []\n",
        "    for image_path in image_paths:\n",
        "        if not os.path.exists(image_path):\n",
        "            import sys\n",
        "            print(f\"Image not found: {image_path}\", file=sys.stderr)\n",
        "            continue\n",
        "        try:\n",
        "            img = load_img(image_path, target_size=target_size, color_mode=color_mode)\n",
        "            img = img_to_array(img) / 255.0  # Normalize\n",
        "            img_features.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "    return np.array(img_features).reshape(-1, *target_size, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icywWt4lLe-i"
      },
      "outputs": [],
      "source": [
        "def validate_features(features, target_shape=(48, 48, 1)):\n",
        "\n",
        "    if features.shape[1:] != target_shape:\n",
        "        print(f\"Validation failed: Expected shape {target_shape}, but got {features.shape[1:]}.\")\n",
        "        return False\n",
        "\n",
        "    if np.any(np.isnan(features)) or np.any(np.isinf(features)):\n",
        "        print(\"Validation failed: Found NaN or infinite values in features.\")\n",
        "        return False\n",
        "\n",
        "    if np.min(features) < 0.0 or np.max(features) > 1.0:\n",
        "        print(\"Validation failed: Feature values are not in the range [0, 1].\")\n",
        "        return False\n",
        "\n",
        "    print(\"Validation passed: All checks passed.\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWeGd1Y-gj9J"
      },
      "outputs": [],
      "source": [
        "# Extract the features from training and testing datasets\n",
        "TARGET_SIZE = (48, 48)\n",
        "train_features = get_features(train['image'],  target_size=TARGET_SIZE)\n",
        "test_features = get_features(test['image'], target_size=TARGET_SIZE)\n",
        "\n",
        "# validation of features train & test\n",
        "\n",
        "if validate_features(train_features) and validate_features(test_features):\n",
        "    print(\"Features validation passed.\")\n",
        "else:\n",
        "    print(\"Features validation failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGglHsdPiAG_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder to training labels\n",
        "label_encoder.fit(train[\"label\"])\n",
        "\n",
        "# Transform both training and testing labels to integer values\n",
        "# 0 to 6 for the 7 classes start from angry to neutral\n",
        "y_train = label_encoder.transform(train[\"label\"])\n",
        "y_test = label_encoder.transform(test[\"label\"])\n",
        "\n",
        "# Convert integer labels to one-hot encoded vectors using Keras\n",
        "# Dynamic exact number of classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "\"\"\"\n",
        "To convert the integer labels to one-hot encoded vectors, we can use the to_categorical function from Keras.\n",
        "This function takes the integer labels and the number of classes as input and returns the one-hot encoded vectors.\n",
        "\"\"\"\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "y_train = to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)\n",
        "\n",
        "# Output the one-hot encoded vectors and classes\n",
        "print(\"One-hot encoded labels (first 5 rows):\")\n",
        "print(y_train[:5])\n",
        "print(\"Classes:\")\n",
        "print(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sRlJekKLe-i"
      },
      "outputs": [],
      "source": [
        "x_train = train_features\n",
        "x_test = test_features\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "299ccx9rLe-j"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(np.argmax(y_train, axis=1)),\n",
        "    y=np.argmax(y_train, axis=1)\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9wJHE8PLe-j"
      },
      "outputs": [],
      "source": [
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Input(shape=INPUT_SHAPE))\n",
        "\n",
        "# First convolutional block\n",
        "# - The 32 filters help the model learn 32 distinct patterns or features from the input data.\n",
        "# - The kernel size (3x3) determines the receptive field used to scan the input.\n",
        "# - ReLU (Rectified Linear Unit) activation introduces non-linearity to enable the model\n",
        "#   to learn complex relationships between features.\n",
        "# This layer extracts low-level features such as edges and textures from the input image.\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "# Add a batch normalization layer immediately after the convolutional layer.\n",
        "# - This layer normalizes the outputs of the convolutional layer to have a mean of 0\n",
        "#   and a standard deviation of 1, which helps stabilize the learning process.\n",
        "# - It reduces sensitivity to weight initialization and allows the model to train faster.\n",
        "# Batch normalization also acts as a regularizer, reducing the chances of overfitting.\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Second convolutional block\n",
        "# - Increase filters to 64\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# - Add a max pooling layer with a pool size of 2x2.\n",
        "# - This layer downsamples the spatial dimensions of the feature maps,\n",
        "# - reducing computation and helping the model focus on dominant features.\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# - Add a dropout layer with a dropout rate of 0.5.\n",
        "# - This randomly sets 50% of the neurons to zero during training to prevent overfitting\n",
        "# - and improve the generalization capability of the model.\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Third convolutional block\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Fourth convolutional block\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Flatten())  # Flatten feature maps\n",
        "\n",
        "# - The large number of neurons (1024) provides the model with significant capacity\n",
        "# - to learn intricate details in the data.\n",
        "model.add(Dense(1024, activation='relu')) # Fully connected layer\n",
        "model.add(Dropout(0.2)) # Dropout\n",
        "\n",
        "# - Each neuron corresponds to one of the 7 emotion classes in the dataset.\n",
        "# - The softmax activation function ensures that the output values represent probabilities\n",
        "# - and sum to 1, making it suitable for multi-class classification tasks.\n",
        "model.add(Dense(7, activation='softmax')) # Output layer\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Complie the model using Adam optimizer and categorical cross-entropy loss\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ThIKeINXMpQ"
      },
      "outputs": [],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Input(shape=INPUT_SHAPE))\n",
        "\n",
        "# Convolutional Input Layer\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.3))\n",
        "\n",
        "# Convolutional HL 2\n",
        "model2.add(Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.3))\n",
        "\n",
        "# Convolutional HL 3\n",
        "model2.add(Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.4))\n",
        "\n",
        "# Global Average Pooling\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "model2.add(Dense(64, activation=\"relu\"))\n",
        "model2.add(Dropout(0.3))\n",
        "\n",
        "# Output Layer\n",
        "model2.add(Dense(7, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model\n",
        "opti = Adam(learning_rate=0.0005)\n",
        "model2.compile(optimizer=opti, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTV5CSwJLe-j"
      },
      "source": [
        "- Validation Loss Fluctuations:\n",
        "- Validation loss fluctuates significantly (e.g., jumping from 1.8796 to 4.0646 and then back to 1.8438), indicating potential overfitting or instability in training.\n",
        "\n",
        "- Drop in Performance in Later Epochs:\n",
        "\t•\tAfter an initial improvement, performance metrics degrade in some epochs (e.g., validation loss increases to 3.9991 in epoch 5), possibly due to overfitting, inadequate regularization, or a mismatch in data preprocessing between training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ataFvjQBjWh6"
      },
      "outputs": [],
      "source": [
        "# Setup for early stopping and learning rate reduction callbacks\n",
        "# - Callback stops training early if validation loss does not improve\n",
        "# - within given number of epochs (50)\n",
        "early_stopping = EarlyStopping(\"val_loss\", patience=50)\n",
        "\n",
        "# Define the ReduceLROnPlateau callback.\n",
        "# - This reduces the learning rate when the validation loss stops improving.\n",
        "# - `monitor='val_loss'`: Monitors the validation loss during training.\n",
        "# - `factor=0.1`: Reduces the learning rate by a factor of 10 when triggered.\n",
        "# - `patience=int(50/4)`: Waits for approximately 12 epochs (1/4 of `patience` for early stopping) without improvement before reducing the learning rate.\n",
        "# - `verbose=1`: Logs messages to the console when the learning rate is reduced.\n",
        "reduce_lr = ReduceLROnPlateau(\"val_loss\", factor=0.1, patience=int(50 / 4), verbose=1)\n",
        "\n",
        "# Train the model\n",
        "# - `x=x_train, y=y_train`: The training data and corresponding labels.\n",
        "# - `batch_size=64`: Specifies the number of training samples processed before the model updates.\n",
        "# - `epochs=40`: The maximum number of times the entire training dataset is processed.\n",
        "# - `verbose=1`: Displays detailed progress information during training.\n",
        "# - `validation_data=(x_test, y_test)`: Specifies the validation dataset for monitoring validation performance.\n",
        "# - `callbacks=[early_stopping, reduce_lr]`: Adds the early stopping and learning rate reduction callbacks\n",
        "# - to dynamically manage training termination and learning rate adjustments.\n",
        "\n",
        "if len(train_features) != len(y_train):\n",
        "    print(\"Length of train_features and y_train are not equal\")\n",
        "else:\n",
        "    model_info = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        epochs=40, # 40 epochs finer tuning\n",
        "        batch_size=128,\n",
        "        verbose=1, # display progress\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nma8Mc9uLe-l"
      },
      "outputs": [],
      "source": [
        "model_info2 = model2.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=40,\n",
        "    verbose=1,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKXer4mckkcS"
      },
      "outputs": [],
      "source": [
        "# Evaluate the accuracy\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Model 1: Test loss: {loss:.4f}, accuracy: {accuracy:.4f}\")\n",
        "\n",
        "loss2, accuracy2 = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Model 2: Test loss: {loss2:.4f}, accuracy: {accuracy2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZL4_yiP00X2"
      },
      "outputs": [],
      "source": [
        "# Save the model structure and weights\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PotmtUf18BRl"
      },
      "outputs": [],
      "source": [
        "# Save the trained model weight in .h5 file\n",
        "model.save_weights('model.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_bsMpKA8Mgp"
      },
      "outputs": [],
      "source": [
        "# Save the complete model in .keras format\n",
        "model.save(\"finalmodel.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCCdm55h94RQ"
      },
      "outputs": [],
      "source": [
        "# Plot the training accuracy and loss graphs\n",
        "accuracy = model_info.history['accuracy']\n",
        "val_accuracy = model_info.history['val_accuracy']\n",
        "loss = model_info.history['loss']\n",
        "val_loss = model_info.history['val_loss']\n",
        "\n",
        "accuracy2 = model_info2.history['accuracy']  # Training accuracy for Model 2\n",
        "val_accuracy2 = model_info2.history['val_accuracy']  # Validation accuracy for Model 2\n",
        "loss2 = model_info2.history['loss']  # Training loss for Model 2\n",
        "val_loss2 = model_info2.history['val_loss']  # Validation loss for Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpJ1j0CxLe-l"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot accuracy comparison\n",
        "plt.figure(figsize=(14, 6))\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, accuracy, label='Model 1 - Accuracy', linestyle='--')\n",
        "plt.plot(epochs, val_accuracy, label='Model 1 - Val Accuracy', linestyle='--')\n",
        "plt.plot(epochs, accuracy2, label='Model 2 - Accuracy', linestyle='-')\n",
        "plt.plot(epochs, val_accuracy2, label='Model 2 - Val Accuracy', linestyle='-')\n",
        "plt.title('Accuracy Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot loss comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, label='Model 1 - Loss', linestyle='--')\n",
        "plt.plot(epochs, val_loss, label='Model 1 - Val Loss', linestyle='--')\n",
        "plt.plot(epochs, loss2, label='Model 2 - Loss', linestyle='-')\n",
        "plt.plot(epochs, val_loss2, label='Model 2 - Val Loss', linestyle='-')\n",
        "plt.title('Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W01--P2WRcJZ"
      },
      "outputs": [],
      "source": [
        "# Test the model on a random image from the test set\n",
        "image_index = random.randint(0, len(test))  # Pick image using random index number\n",
        "print(\"Original Output:\", test['label'][image_index]) # Display original label\n",
        "\n",
        "# Predict the label using trained model\n",
        "pred = model.predict(x_test[image_index].reshape(1, 48, 48, 1)) # Reshape to mathc model dimensions\n",
        "\n",
        "# Decode predicted label back to original string with LabelEncoder\n",
        "prediction_label = label_encoder.inverse_transform([pred.argmax()])[0]\n",
        "print(\"Predicted Output:\", prediction_label) # Display predicted label\n",
        "\n",
        "# Display test image in grayscale to see input\n",
        "plt.imshow(x_test[image_index].reshape(48, 48), cmap='gray');"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}